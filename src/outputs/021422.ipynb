{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motion Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positive class: turning car at intersection (22 tracks in total, 16 for training, 6 for testing) \\\n",
    "Negative class: All other tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features: start and end bounding box coordinates (x1, x2, y1, y2)\n",
    "\n",
    "| # negative training data | mean average rank | total # test data |\n",
    "| --- | --- | ---- |\n",
    "| 16 | 41 | 212 |\n",
    "| 32 | 26 | 196 |\n",
    "| 48 | 22 | 180 | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features: start and end bounding box centroids (x, y)\n",
    "\n",
    "| # negative training data | mean average rank | total # test data |\n",
    "| --- | --- | ---- |\n",
    "| 16 | 45 | 212 |\n",
    "| 32 | 29 | 196 |\n",
    "| 48 | 23 | 180 | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features: start and end bounding box coordinates (8) + dense optical flow (256*3, PCA down to 16)\n",
    "\n",
    "| # negative training data | mean average rank | total # test data |\n",
    "| --- | --- | ---- |\n",
    "| 16 | 35 | 212 |\n",
    "| 32 | 25 | 196 |\n",
    "| 48 | 22 | 180 | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving car\n",
    "![title](/mmfs1/gscratch/balazinska/enhaoz/complex_event_video/src/outputs/optical_flow.png)\n",
    "\n",
    "# Static car\n",
    "![title](/mmfs1/gscratch/balazinska/enhaoz/complex_event_video/src/outputs/optical_flow2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features: start and end bounding box coordinates (8) + optical flow (Lucas-Kanade method, downsampling to 16*16, then PCA down to 16)\n",
    "\n",
    "| # negative training data | mean average rank | total # test data |\n",
    "| --- | --- | ---- |\n",
    "| 16 | 29 | 212 |\n",
    "| 32 | 23 | 196 |\n",
    "| 48 | 20 | 180 | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features: optical flow (Lucas-Kanade method, downsampling to 16*16, then PCA down to 16)\n",
    "\n",
    "| # negative training data | mean average rank | total # test data |\n",
    "| --- | --- | ---- |\n",
    "| 16 | 30 | 212 |\n",
    "| 32 | 23 | 196 |\n",
    "| 48 |  | 180 | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features: trail model, spatial translation and scale-absolute retrieval \n",
    "\n",
    "| # negative training data | mean average rank | total # test data |\n",
    "| --- | --- | ---- |\n",
    "| - | 10 | 228 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicates on Objects "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sampling rate: 30, test size: 300 \\\n",
    "Query: car in the bottom-left of the frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VOCAL\n",
    "centroid_x <= 480 and 270 <= centroid_y <= 540\n",
    "\n",
    "| # training data | 10 | 20 | 50 | 100 | 150 | 200 |\n",
    "| --- | --- | ---- | --- | --- | ---- | --- |\n",
    "| acc |  0.881 | 0.922 | 0.943 | 0.955 | 0.963 | 0.969 |\n",
    "| balanced_acc | 0.880 | 0.921 | 0.942 | 0.954 | 0.963 | 0.969 |        \n",
    "| f1 | 0.883 | 0.925 | 0.946 | 0.957 | 0.965 | 0.970 |\n",
    "|precision| 0.859 | 0.904 | 0.930 | 0.944 | 0.955 | 0.962 |\n",
    "|recall |  0.924 | 0.955 | 0.968 | 0.975 | 0.979 | 0.982 |\n",
    "| training time | 0.096 | 0.095 | 0.095 | 0.098 | 0.098 | 0.099 | \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet50\n",
    "* input: entire video frame\n",
    "* data transform: transforms.Resize((256,256)),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "* batch size: 8\n",
    "* num_epochs: 25 \n",
    "* Need to double check\n",
    "\n",
    "| # training data | 10 | 20 | 50 | 100 | 150 | 200 |\n",
    "| --- | --- | ---- | --- | --- | ---- | --- |\n",
    "| acc |  0.502 | 0.512 | 0.522 | 0.534 | 0.541 | 0.547 |\n",
    "| balanced_acc | 0.497 | 0.509 | 0.521 | 0.532 | 0.541 | 0.546 |        \n",
    "| f1 | 0.406 | 0.473 | 0.506 | 0.524 | 0.537 | 0.544 |\n",
    "|precision| 0.441 | 0.487 | 0.516 | 0.532 | 0.541 | 0.549 |\n",
    "|recall |  0.511 | 0.546 | 0.557 | 0.563 | 0.573 | 0.574 |\n",
    "| training time | 45.0 | 45.5 | 46.7 | 48.7 | 50.8 | 53.1 | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/mmfs1/gscratch/balazinska/enhaoz/complex_event_video/src/outputs/021422.ipynb Cell 14'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bvscode/mmfs1/gscratch/balazinska/enhaoz/complex_event_video/src/outputs/021422.ipynb#ch0000013vscode-remote?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmotion\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bvscode/mmfs1/gscratch/balazinska/enhaoz/complex_event_video/src/outputs/021422.ipynb#ch0000013vscode-remote?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mIPython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdisplay\u001b[39;00m \u001b[39mimport\u001b[39;00m HTML\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bvscode/mmfs1/gscratch/balazinska/enhaoz/complex_event_video/src/outputs/021422.ipynb#ch0000013vscode-remote?line=5'>6</a>\u001b[0m tracks \u001b[39m=\u001b[39m ingest_mot()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bvscode/mmfs1/gscratch/balazinska/enhaoz/complex_event_video/src/outputs/021422.ipynb#ch0000013vscode-remote?line=6'>7</a>\u001b[0m pos_ids \u001b[39m=\u001b[39m [\u001b[39m981\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bvscode/mmfs1/gscratch/balazinska/enhaoz/complex_event_video/src/outputs/021422.ipynb#ch0000013vscode-remote?line=7'>8</a>\u001b[0m topk_ids \u001b[39m=\u001b[39m trail_based_match_inference(tracks, pos_ids)\n",
      "File \u001b[0;32m/mmfs1/gscratch/balazinska/enhaoz/complex_event_video/src/motion.py:412\u001b[0m, in \u001b[0;36mingest_mot\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='file:///mmfs1/gscratch/balazinska/enhaoz/complex_event_video/src/motion.py?line=410'>411</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mingest_mot\u001b[39m():\n\u001b[0;32m--> <a href='file:///mmfs1/gscratch/balazinska/enhaoz/complex_event_video/src/motion.py?line=411'>412</a>\u001b[0m     tracks \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mloadtxt(\u001b[39m\"\u001b[39;49m\u001b[39m/gscratch/balazinska/enhaoz/complex_event_video/data/MOT20/train/MOT20-05/gt/gt.txt\u001b[39;49m\u001b[39m\"\u001b[39;49m, delimiter\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m    <a href='file:///mmfs1/gscratch/balazinska/enhaoz/complex_event_video/src/motion.py?line=412'>413</a>\u001b[0m     tracks \u001b[39m=\u001b[39m tracks[:, :\u001b[39m6\u001b[39m]\n\u001b[1;32m    <a href='file:///mmfs1/gscratch/balazinska/enhaoz/complex_event_video/src/motion.py?line=413'>414</a>\u001b[0m     tracks[:, \u001b[39m4\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tracks[:, \u001b[39m2\u001b[39m]\n",
      "File \u001b[0;32m/gscratch/balazinska/enhaoz/env/lib/python3.8/site-packages/numpy/lib/npyio.py:1163\u001b[0m, in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, like)\u001b[0m\n\u001b[1;32m   <a href='file:///gscratch/balazinska/enhaoz/env/lib/python3.8/site-packages/numpy/lib/npyio.py?line=1158'>1159</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   <a href='file:///gscratch/balazinska/enhaoz/env/lib/python3.8/site-packages/numpy/lib/npyio.py?line=1159'>1160</a>\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWrong number of columns at line \u001b[39m\u001b[39m{\u001b[39;00mlineno\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   <a href='file:///gscratch/balazinska/enhaoz/env/lib/python3.8/site-packages/numpy/lib/npyio.py?line=1160'>1161</a>\u001b[0m     \u001b[39m# Convert each value according to its column, then pack it\u001b[39;00m\n\u001b[1;32m   <a href='file:///gscratch/balazinska/enhaoz/env/lib/python3.8/site-packages/numpy/lib/npyio.py?line=1161'>1162</a>\u001b[0m     \u001b[39m# according to the dtype's nesting, and store it.\u001b[39;00m\n\u001b[0;32m-> <a href='file:///gscratch/balazinska/enhaoz/env/lib/python3.8/site-packages/numpy/lib/npyio.py?line=1162'>1163</a>\u001b[0m     chunk\u001b[39m.\u001b[39mappend(packer(convert_row(words)))\n\u001b[1;32m   <a href='file:///gscratch/balazinska/enhaoz/env/lib/python3.8/site-packages/numpy/lib/npyio.py?line=1163'>1164</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunk:  \u001b[39m# The islice is empty, i.e. we're done.\u001b[39;00m\n\u001b[1;32m   <a href='file:///gscratch/balazinska/enhaoz/env/lib/python3.8/site-packages/numpy/lib/npyio.py?line=1164'>1165</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/gscratch/balazinska/enhaoz/env/lib/python3.8/site-packages/numpy/lib/npyio.py:1142\u001b[0m, in \u001b[0;36mloadtxt.<locals>.convert_row\u001b[0;34m(vals, _conv)\u001b[0m\n\u001b[1;32m   <a href='file:///gscratch/balazinska/enhaoz/env/lib/python3.8/site-packages/numpy/lib/npyio.py?line=1140'>1141</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconvert_row\u001b[39m(vals, _conv\u001b[39m=\u001b[39mconverters[\u001b[39m0\u001b[39m]):\n\u001b[0;32m-> <a href='file:///gscratch/balazinska/enhaoz/env/lib/python3.8/site-packages/numpy/lib/npyio.py?line=1141'>1142</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39m*\u001b[39m\u001b[39mmap\u001b[39;49m(_conv, vals)]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.append(\"/mmfs1/gscratch/balazinska/enhaoz/complex_event_video/src\")\n",
    "from motion import *\n",
    "from IPython.display import HTML\n",
    "\n",
    "tracks = ingest_mot()\n",
    "pos_ids = [981]\n",
    "topk_ids = trail_based_match_inference(tracks, pos_ids)\n",
    "# print(topk_ids)\n",
    "query_filepaths = visualize_track_mot(tracks, pos_ids)\n",
    "results_filepaths = visualize_track_mot(tracks, pos_ids, topk_ids)\n",
    "print(\"query_filepaths\", query_filepaths)\n",
    "print(\"results_filepaths\", results_filepaths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "530e70a2bef1421a915ad2abec0bd1ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridspecLayout(children=(Output(layout=Layout(grid_area='widget001')), Output(layout=Layout(grid_area='widget0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import Output, GridspecLayout\n",
    "from IPython import display\n",
    "\n",
    "query_filepaths = ['/mmfs1/gscratch/balazinska/enhaoz/complex_event_video/tmp/track_mot/000001.mp4', '/mmfs1/gscratch/balazinska/enhaoz/complex_event_video/tmp/track_mot/000002.mp4']\n",
    "grid = GridspecLayout(1, len(query_filepaths))\n",
    "\n",
    "for i, filepath in enumerate(query_filepaths):\n",
    "    out = Output()\n",
    "    with out:\n",
    "        display.display(display.Video(filepath, embed=True))\n",
    "    grid[0, i] = out\n",
    "\n",
    "grid"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f0728be81bb21a0ef1bd9696adbcb89c74a9aedaac598689ad813edcff53ab11"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
