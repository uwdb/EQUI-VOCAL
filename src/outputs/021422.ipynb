{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motion Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positive class: turning car at intersection (22 tracks in total, 16 for training, 6 for testing) \\\n",
    "Negative class: All other tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features: start and end bounding box coordinates (x1, x2, y1, y2)\n",
    "\n",
    "| # negative training data | mean average rank | total # test data |\n",
    "| --- | --- | ---- |\n",
    "| 16 | 41 | 212 |\n",
    "| 32 | 26 | 196 |\n",
    "| 48 | 22 | 180 | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features: start and end bounding box centroids (x, y)\n",
    "\n",
    "| # negative training data | mean average rank | total # test data |\n",
    "| --- | --- | ---- |\n",
    "| 16 | 45 | 212 |\n",
    "| 32 | 29 | 196 |\n",
    "| 48 | 23 | 180 | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features: start and end bounding box coordinates (8) + dense optical flow (256*3, PCA down to 16)\n",
    "\n",
    "| # negative training data | mean average rank | total # test data |\n",
    "| --- | --- | ---- |\n",
    "| 16 | 35 | 212 |\n",
    "| 32 | 25 | 196 |\n",
    "| 48 | 22 | 180 | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving car\n",
    "![title](/mmfs1/gscratch/balazinska/enhaoz/complex_event_video/src/outputs/optical_flow.png)\n",
    "\n",
    "# Static car\n",
    "![title](/mmfs1/gscratch/balazinska/enhaoz/complex_event_video/src/outputs/optical_flow2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features: start and end bounding box coordinates (8) + optical flow (Lucas-Kanade method, downsampling to 16*16, then PCA down to 16)\n",
    "\n",
    "| # negative training data | mean average rank | total # test data |\n",
    "| --- | --- | ---- |\n",
    "| 16 | 29 | 212 |\n",
    "| 32 | 23 | 196 |\n",
    "| 48 | 20 | 180 | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features: optical flow (Lucas-Kanade method, downsampling to 16*16, then PCA down to 16)\n",
    "\n",
    "| # negative training data | mean average rank | total # test data |\n",
    "| --- | --- | ---- |\n",
    "| 16 | 30 | 212 |\n",
    "| 32 | 23 | 196 |\n",
    "| 48 |  | 180 | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features: trail model, spatial translation and scale-absolute retrieval \n",
    "\n",
    "| # negative training data | mean average rank | total # test data |\n",
    "| --- | --- | ---- |\n",
    "| - | 10 | 228 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicates on Objects "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sampling rate: 30, test size: 300 \\\n",
    "Query: car in the bottom-left of the frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VOCAL\n",
    "centroid_x <= 480 and 270 <= centroid_y <= 540\n",
    "\n",
    "| # training data | 10 | 20 | 50 | 100 | 150 | 200 |\n",
    "| --- | --- | ---- | --- | --- | ---- | --- |\n",
    "| acc |  0.881 | 0.922 | 0.943 | 0.955 | 0.963 | 0.969 |\n",
    "| balanced_acc | 0.880 | 0.921 | 0.942 | 0.954 | 0.963 | 0.969 |        \n",
    "| f1 | 0.883 | 0.925 | 0.946 | 0.957 | 0.965 | 0.970 |\n",
    "|precision| 0.859 | 0.904 | 0.930 | 0.944 | 0.955 | 0.962 |\n",
    "|recall |  0.924 | 0.955 | 0.968 | 0.975 | 0.979 | 0.982 |\n",
    "| training time | 0.096 | 0.095 | 0.095 | 0.098 | 0.098 | 0.099 | \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet50\n",
    "* input: entire video frame\n",
    "* data transform: transforms.Resize((256,256)),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "* batch size: 8\n",
    "* num_epochs: 25 \n",
    "* Need to double check\n",
    "\n",
    "| # training data | 10 | 20 | 50 | 100 | 150 | 200 |\n",
    "| --- | --- | ---- | --- | --- | ---- | --- |\n",
    "| acc |  0.502 | 0.512 | 0.522 | 0.534 | 0.541 | 0.547 |\n",
    "| balanced_acc | 0.497 | 0.509 | 0.521 | 0.532 | 0.541 | 0.546 |        \n",
    "| f1 | 0.406 | 0.473 | 0.506 | 0.524 | 0.537 | 0.544 |\n",
    "|precision| 0.441 | 0.487 | 0.516 | 0.532 | 0.541 | 0.549 |\n",
    "|recall |  0.511 | 0.546 | 0.557 | 0.563 | 0.573 | 0.574 |\n",
    "| training time | 45.0 | 45.5 | 46.7 | 48.7 | 50.8 | 53.1 | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Person stands up\n",
    "\n",
    "all training samples: \n",
    "* ResNet 18, finetuning only the final layer, 25 epochs: 67.7%\n",
    "* ResNet 18, finetuning all layers, 25 epochs: 68.9%\n",
    "\n",
    "200 samples: \n",
    "* ResNet 18, finetuning only the final layer, adam optimizer, 25 epochs: 56.3%\n",
    "* ResNet 18, finetuning only the final layer, SGD optimizer, 25 epochs: 57.9%\n",
    "* ResNet 18, finetuning only the final layer, SGD optimizer, random horizontal flip, 25 epochs: 58.8%\n",
    "\n",
    "all training samples; refined: \n",
    "* ResNet 18, finetuning only the final layer, random horizontal flip, 25 epochs: 72.5%\n",
    "* ResNet 18, finetuning all layers, random horizontal flip, 25 epochs: 82.2%\n",
    "\n",
    "200 samples; refined: \n",
    "* ResNet 18, finetuning only the final layer, random horizontal flip, 25 epochs: 63.8+/-3.1%\n",
    "* ResNet 18, finetuning all layers, random horizontal flip, 25 epochs: 67.9+/-4.2%\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VOCAL\n",
    "Each experiment repeated 20 times \n",
    "\n",
    "* Original \n",
    "\n",
    "| # training data | 10  | 20    | 50    | 100   | 150   | 200   | All (6980) |\n",
    "| ---           | ---   | ---   | ---   | ---   | ---   | ---   | ---   |\n",
    "| acc           | 0.533 | 0.564 | 0.648 | 0.695 | 0.715 | 0.730 | 0.780 |\n",
    "| balanced_acc  | 0.533 | 0.564 | 0.648 | 0.695 | 0.715 | 0.730 | 0.780 |\n",
    "| f1            | 0.539 | 0.573 | 0.658 | 0.704 | 0.725 | 0.740 | 0.781 |\n",
    "|precision      | 0.527 | 0.557 | 0.639 | 0.684 | 0.699 | 0.713 | 0.777 |\n",
    "|recall         | 0.570 | 0.606 | 0.689 | 0.732 | 0.757 | 0.773 | 0.785 |\n",
    "| training time | 0.078 | 0.078 | 0.080 | 0.084 | 0.089 | 0.094 | 0.777 |\n",
    "\n",
    "* Refined\n",
    "\n",
    "| # training data | 10  | 20    | 50    | 100   | 150   | 200   | All (3504) |\n",
    "| ---           | ---   | ---   | ---   | ---   | ---   | ---   | ---   |\n",
    "| acc           | 0.544 | 0.638 | 0.680 | 0.697 | 0.740 | 0.751 | 0.800 |\n",
    "| balanced_acc  | 0.544 | 0.638 | 0.680 | 0.697 | 0.740 | 0.751 | 0.800 |\n",
    "| f1            | 0.556 | 0.677 | 0.699 | 0.706 | 0.758 | 0.763 | 0.793 |\n",
    "|precision      | 0.535 | 0.614 | 0.666 | 0.685 | 0.713 | 0.729 | 0.823 |\n",
    "|recall         | 0.612 | 0.765 | 0.751 | 0.735 | 0.814 | 0.803 | 0.764 |\n",
    "| training time | 0.081 | 0.080 | 0.083 | 0.087 | 0.091 | 0.095 | 0.405 |\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f0728be81bb21a0ef1bd9696adbcb89c74a9aedaac598689ad813edcff53ab11"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
